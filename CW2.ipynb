{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mushroom picking is a popular pastime. Wild mushrooms vary in edibility, from edible and pleasant-tasting to deadly poisonous. Correct identification is difficult for the layman, and different mushrooms can easily be confused with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this coursework is to create a Machine Learning model to classify mushroom specimens as edible or poisonous. This model must be highly credible and accurate, since the nature of its task means errors could mean fatalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Mushroom](https://archive.ics.uci.edu/ml/datasets/mushroom) dataset is a well-known dataset for classification purposes. It contains more than 8,000 instances of specimens in the *Agaricus* and *Lepiota* genera of mushrooms. Each instance is classified as either *edible* or *poisonous*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This copy of the Mushroom dataset was retrieved from the [Wolfram Data Repository](https://datarepository.wolframcloud.com/resources/Sample-Data-Mushroom-Classification) on roughly November 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research & Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper [*Data Mining on Mushroom Database*](http://csis.pace.edu/~ctappert/srd2008/b2.pdf) makes use of the Mushroom dataset. The authors worked to find the most effective Machine Learning model to use for Mushroom, with preliminary results showing that the most effective one used was a Decision Tree algorithm (J48). Test data was split into 2 sets, on which the model reached 99.6% and 100% accuracy, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper's goal is not dissimilar to that of this coursework. The authors built a user-facing web application powered by the Decision Tree model, which returns a mushroom's edibility given some attributes by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *8. Limitations and Opportunities for Research*, the authors state that the `StalkRoot` attribute, which is known to be about 30% missing, was not removed except in the case of one particular algorithm (PRISM) which was unable to process missing values. It is noted that 'an acceptable level of accuracy was reached regardless of the missing data'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the Decision Tree model are not explained, other than that the tree is unpruned. Unpruned trees are prone to overfitting, a possibility which is not discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper provides no exploration of the dataset, very little explanation of how the data was prepared, and no visualisation. Although its primary focus is not the dataset itself but rather the Machine Learning algorithms used, this means little can be known about what preparatory measures were undertaken with the data to produce the high degree of accuracy achieved by the model. Most of Mushroom's features are categorical and therefore uninterpretable by most Machine Learning algorithms, so the data was certainly processed; but this processing is not explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-3c5c9653bb22>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Import libraries\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('data/mushroom.csv')\n",
    "df.iloc[:5,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset contains {df.shape[0]} rows')\n",
    "print(f'and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but two features are of `object` type: these are all categorical variables, having discrete values. They will need to be handled in order to be properly interpreted by most Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some attributes, such as `GillAttachment` and `RingNumber`, apparently show very little relation to the class variable. Others, such as `GillColor` & `Odor`, appear to be important features. For example, a `GillColor` of *buff* and an `Odor` of *foul* are apparently important predictors of poisonous mushrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4 subplots\n",
    "plt.figure(figsize=(14,11))\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('GillAttachment vs Class')\n",
    "sns.countplot(data=df,x='GillAttachment',hue='Class')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('RingNumber vs Class')\n",
    "sns.countplot(data=df,x='RingNumber',hue='Class')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('GillColor vs Class')\n",
    "sns.countplot(data=df,x='GillColor',hue='Class')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Odor vs Class')\n",
    "sns.countplot(data=df,x='Odor',hue='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset's class distribution is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class label counts\n",
    "edible = len(df[df.Class=='edible'])\n",
    "poisonous = len(df[df.Class=='poisonous'])\n",
    "\n",
    "# Class label proportions\n",
    "ediblePC = round(edible/df.shape[0]*100,2)\n",
    "poisonousPC = round(poisonous/df.shape[0]*100,2)\n",
    "\n",
    "print(f'Edible: {edible} ({ediblePC}%)')\n",
    "print(f'Poisonous: {poisonous} ({poisonousPC}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class label proportions\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(rc={'figure.figsize':(9,7)})\n",
    "\n",
    "sns.countplot(x='Class',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mushroom is known to contain missing values. They can be spotted by a knowledgeable eye in the following output: among the listed unique values of the `StalkRoot` feature is a value `Missing[]`. As previously mentioned, the dataset was downloaded from the Wolfram Data Repository, and according to the [Wolfram Language Reference](https://reference.wolfram.com/language/ref/Missing.html), `Missing[]` is the standard notation for missing values in the Wolfram Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of each column if they number 5 or fewer\n",
    "for i in df.columns:\n",
    "    if len(df[i].unique()) <= 5:\n",
    "        print (f'{len(df[i].unique())} unique values in {i}: {df[i].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Unique values in StalkRoot: {df[\"StalkRoot\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be sure that there are no more missing values in the dataset by converting any `Missing[]` values into a more traditional `None`, and then checking the data frame for null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert Missing[] values to None\n",
    "def missingToNone(value):\n",
    "    if value == 'Missing[]':\n",
    "        return None\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to data frame\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].apply(missingToNone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for missing values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of missing values in StalkRoot: {round(((df[\"StalkRoot\"].isnull().sum() / df.shape[0]) * 100), 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the proportion of missing values is not significant, the StalkRoot feature can be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Variance Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following output reveals that the feature `VeilType` contains only 1 unique value. This makes it a *zero-variance predictor* which is of no use for modelling, so it can be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values per feature\n",
    "for i in df.columns:\n",
    "    print (i,len(df[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop VeilType feature\n",
    "df.drop(['VeilType'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features in the dataset are subject to one-hot encoding with Pandas' `get_dummies` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of categorical features\n",
    "non_cat_variables = ['Bruises', 'RingNumber', 'Class']\n",
    "cat_variables = set(df.columns) - set(non_cat_variables)\n",
    "\n",
    "# New data frame for encoded features\n",
    "df_encoded = pd.get_dummies(df, columns=cat_variables)\n",
    "df_encoded.iloc[:5, :6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in the class label being shifted from the end of the data frame to near the beginning, so it is moved back to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move class label to end of data frame\n",
    "target = df['Class']\n",
    "df_encoded.drop(labels=['Class'], axis=1, inplace=True)\n",
    "df_encoded.insert(len(df_encoded.columns), 'Class', target)\n",
    "df_encoded.iloc[:5, -3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains one Boolean feature. To make this value consistent with the encoded categorical variables, and to preclude any cross-algorithm differences in interpretation of Booleans, the feature is encoded into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode into an integer\n",
    "def toInteger(value):\n",
    "    return int(value)\n",
    "\n",
    "# Apply\n",
    "df_encoded['Bruises'] = df_encoded['Bruises'].apply(toInteger)\n",
    "df.iloc[:5, :1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class label is also a categorical variable. It is a requirement of most machine learning models that the class label is encoded into an integer. This can be achieved with scikit-learn's `LabelEncoder`, which also allows the label values to be transformed back into their original string representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df_encoded.Class = le.fit_transform(df.Class)\n",
    "df_encoded.iloc[:5, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_original = le.inverse_transform(df_encoded.Class)\n",
    "labels_original[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace original data frame\n",
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into training and testing sets, representing 80% and 20% of the data respectively. Sampling is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate class label from input\n",
    "X = df.iloc[:,:(df.shape[1]-1)]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class distribution in the testing and training sets is roughly identical to the dataset overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='poly',gamma='auto',C=1)\n",
    "\n",
    "# Train\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = svc.score(X_test, y_test)\n",
    "print(f'Accuracy: {round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant improvement in accuracy can be achieved by tuning the model's C value, with perfect accuracy being achieved with a C of around 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 40\n",
    "svc = SVC(kernel='poly',gamma='auto',C=50)\n",
    "\n",
    "# Train\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = svc.score(X_test, y_test)\n",
    "print(f'Accuracy: {round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# Train\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = dtc.score(X_test,y_test)\n",
    "print(f'{round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initial run with a `max_depth` of 2 yields an unimpressive accuracy compared with the SVM classifier's first run, but the model's accuracy can be improved by tuning the `max_depth`. The model achieves perfect accuracy at a depth of between 5 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracies by max_depth, up to 9\n",
    "max_depth_vals = list(range(1, 10))\n",
    "accuracy_list = []\n",
    "for max_depth in max_depth_vals:\n",
    "    dtc = DecisionTreeClassifier(max_depth = max_depth, random_state = 0)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    accuracy = dtc.score(X_test, y_test)\n",
    "    accuracy_list.append(accuracy)\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracies to data frame\n",
    "depth_accuracies = list(zip(max_depth_vals, accuracy_list))\n",
    "results = pd.DataFrame(data=depth_accuracies, columns=['max_depth','accuracy'])\n",
    "results.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise accuracies\n",
    "ax = sns.lineplot(x=\"max_depth\", y=\"accuracy\", data=results, marker=\"o\")\n",
    "ax.set(xlabel='Tree Depth', ylabel='Accuracy')\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update original classifier\n",
    "dtc = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "\n",
    "# Train\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features identified as most important by the Decision Tree model do not appear to include those judged by eye as such in the visualisations in [Data Preparation](#Data_Preparation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features by importance\n",
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(dtc.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False)\n",
    "importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1)\n",
    "\n",
    "# Train\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = rfc.score(X_test, y_test)\n",
    "print(f'Accuracy: {round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is somewhat difficult to produce a wrong prediction from the Random Forest model; on some runs it achieves perfect accuracy with even 1 estimator. The most important features identified on some runs include those identified in the visualisations in [Data Preparation](#Data_Preparation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(rfc.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False)\n",
    "importances.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}